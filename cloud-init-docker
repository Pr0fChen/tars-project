#!/bin/bash
sudo -i

# 1) Mise à jour du système
apt-get update && apt-get upgrade -y

# 2) Création d'un script pour l'installation de Docker et Docker-Compose
cat << 'EOF' > /root/install_docker.sh
#!/bin/bash

apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common sudo
curl -fsSL https://download.docker.com/linux/$(. /etc/os-release; echo "$ID")/gpg | sudo apt-key add -
add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/$(. /etc/os-release; echo "$ID") $(lsb_release -cs) stable"
apt-get update
apt-get install docker-ce
curl -L https://github.com/docker/compose/releases/download/1.19.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
docker-compose --version

curl -fsSL https://get.docker.com/ -o get-docker.sh
sh get-docker.sh
EOF

 # 3) Rendre exécutable le script et l'exécuter                                               
chmod u+x /root/install_docker.sh
/root/install_docker.sh

# 4) Création du Dockerfile
cat << 'EOF' > /root/Dockerfile
# 1. Image de base légère avec Python 3
FROM python:3.12-slim

# 2. Crée et positionne-toi dans /app
WORKDIR /app

# 3. Copie des dépendances et installation
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# 4. Copie de ton code
COPY tars_brain_server.py ./

# 5. Expose le port Flask
EXPOSE 5000

# 6. Commande de démarrage
CMD ["gunicorn", "-b", "0.0.0.0:5000", "tars_brain_server:app"]
EOF

# 5) Création du fichier requirements.txt
cat << 'EOF' > /root/requirements.txt
flask
openai>=1.0.0
gunicorn
EOF

# 6) Création du script tars_brain_server.py
cat << 'EOF' > /root/tars_brain_server.py
# tars_brain_server.py
from flask import Flask, request, jsonify
import os
from openai import OpenAI

app = Flask(__name__)

# Instancier le client avec ta clé
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@app.route('/query', methods=['POST'])
def handle_query():
    data = request.get_json()
    user_text = data.get('text', '')

    # Préparation du system prompt enrichi pour la personnalité
    system_prompt = (
        "Vous êtes TARS, robot tactique de l’expédition Interstellar. "
        "Votre voix est concise, méthodique et légèrement sarcastique. "
        "Vous commencez vos réponses positives par « Affirmatif » et vos refus par « Négatif ». "
        "Vous n’aimez pas les digressions : allez toujours droit à l’essentiel. "
        "Vous ajoutez parfois une pointe d’humour noir si le contexte s’y prête, mais sans perdre en efficacité. "
        "Ne jamais laisser transparaître d’émotion humaine exagérée. "
        "Conservez toujours un ton professionnel et proactif. "
        "Vous avez exactement le même comportement que le robot TARS dans le film Interstellar."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user",   "content": user_text}
    ]

    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=150,
            temperature=0.7,
        )
        answer = resp.choices[0].message.content.strip()
    except Exception as e:
        answer = f"Error: {e}"

    return jsonify({"response": answer})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
EOF

# 6) Création de l'image tars-server
 docker build -t tars-server /root/
